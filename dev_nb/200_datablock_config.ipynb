{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.datasets import URLs, untar_data\n",
    "from pathlib import Path\n",
    "import torch, re, PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(x, funcs, *args, order_key='_order', **kwargs):\n",
    "    key = lambda o: getattr(o, order_key, 0)\n",
    "    for f in sorted(listify(funcs), key=key): x = f(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemList():\n",
    "    def __init__(self, items, tfms=None): self.items,self.tfms = listify(items),tfms\n",
    "    def  get(self, i): return i\n",
    "    def _get(self, i): return compose(self.get(i), self.tfms)\n",
    "    def __getitem__(self, idx):\n",
    "        try: return self._get(self.items[idx])\n",
    "        except TypeError:\n",
    "            if isinstance(idx[0],bool):\n",
    "                assert len(idx)==len(self) # bool mask\n",
    "                return [self._get(o) for m,o in zip(idx,self.items) if m]\n",
    "            return [self._get(self.items[i]) for i in idx]\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return iter(self.items)\n",
    "    def __setitem__(self, i, o): self.items[i] = o\n",
    "    def __delitem__(self, i): del(self.items[i])\n",
    "    def __repr__(self):\n",
    "        res = f'{self.__class__.__name__} ({len(self)} items)\\n{self.items[:10]}'\n",
    "        if len(self)>10: res = res[:-1]+ '...]'\n",
    "        return res\n",
    "    def new(self, items, cls=None):\n",
    "        if cls is None: cls=self.__class__\n",
    "        return cls(items, tfms=self.tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledData():\n",
    "    def process(self, il, proc): return il.new(compose(il.items, proc))\n",
    "\n",
    "    def __init__(self, x, y, proc_x=None, proc_y=None):\n",
    "        self.x,self.y = self.process(x, proc_x),self.process(y, proc_y)\n",
    "        self.proc_x,self.proc_y = proc_x,proc_y\n",
    "        \n",
    "    def __repr__(self): return f'{self.__class__.__name__}\\nx: {self.x}\\ny: {self.y}\\n'\n",
    "    def __getitem__(self,idx): return self.x[idx],self.y[idx]\n",
    "    def __len__(self): return len(self.x)\n",
    "    \n",
    "    def x_obj(self, idx): return self.obj(self.x, idx, self.proc_x)\n",
    "    def y_obj(self, idx): return self.obj(self.y, idx, self.proc_y)\n",
    "    \n",
    "    def obj(self, items, idx, procs):\n",
    "        isint = isinstance(idx, int) or (isinstance(idx,torch.LongTensor) and not idx.ndim)\n",
    "        item = items[idx]\n",
    "        for proc in reversed(listify(procs)):\n",
    "            item = proc.deproc1(item) if isint else proc.deprocess(item)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBlock():\n",
    "    _input_cls = ItemList\n",
    "    _label_cls = ItemList\n",
    "    def download(self):         raise NotImplementedError\n",
    "    def get_items(self, path):  raise NotImplementedError\n",
    "    def split(self, items):     raise NotImplementedError\n",
    "    def label(self, items):     raise NotImplementedError\n",
    "        \n",
    "    def __init__(self, path=None, tfms=None, proc_x=None, proc_y=None):\n",
    "        self.path = self.download()\n",
    "        items = ItemList(self.get_items(path or self.path))\n",
    "        split_idx = self.split(items)\n",
    "        labels = ItemList(self.label(items))\n",
    "        x_train,x_valid = map(lambda o: self._input_cls(items[o], tfms=tfms), split_idx)\n",
    "        y_train,y_valid = map(lambda o: self._label_cls(labels[o]), split_idx)\n",
    "        self.train = LabeledData(x_train, y_train, proc_x=proc_x, proc_y=proc_y)\n",
    "        self.valid = LabeledData(x_valid, y_valid, proc_x=proc_x, proc_y=proc_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageList(ItemList):\n",
    "    def get(self, fn): return PIL.Image.open(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def setify(o): return o if isinstance(o,set) else set(listify(o))\n",
    "\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res\n",
    "\n",
    "def get_files(path, extensions=None, recurse=False, include=None):\n",
    "    path = Path(path)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
    "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
    "            res += _get_files(p, f, extensions)\n",
    "        return res\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        return _get_files(path, f, extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimetypes\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_files(path, include=None):\n",
    "    return get_files(path, extensions=image_extensions, recurse=True, include=include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_splitter(items, valid_pct=0.2, seed=None): \n",
    "    if seed is not None: torch.manual_seed(seed)\n",
    "    rand_idx = torch.randperm(len(items))\n",
    "    cut = int(valid_pct * len(items))\n",
    "    return rand_idx[:cut],rand_idx[cut:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_from_func(items, func):\n",
    "    return [func(o) for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_from_re(items, pat):\n",
    "    pat = re.compile(pat)\n",
    "    def _inner(o):\n",
    "        res = pat.search(str(o))\n",
    "        assert res,f'Failed to find \"{pat}\" in \"{s}\"'\n",
    "        return res.group(1)\n",
    "    return label_from_func(items, _inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetsData(DataBlock):\n",
    "    _input_cls = ImageList\n",
    "    \n",
    "    def download(self):        return untar_data(URLs.PETS)\n",
    "    def get_items(self, path): return get_image_files(path/\"images\")\n",
    "    def split(self, items):    return random_splitter(items)\n",
    "    def label(self, items):    return label_from_re(items, pat = r'/([^/]+)_\\d+.jpg$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PetsData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,cls = data.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rgb(item): return item.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(): _order=0\n",
    "\n",
    "class ResizeFixed(Transform):\n",
    "    _order=10\n",
    "    def __init__(self,size):\n",
    "        if isinstance(size,int): size=(size,size)\n",
    "        self.size = size\n",
    "        \n",
    "    def __call__(self, item): return item.resize(self.size, PIL.Image.BILINEAR)\n",
    "\n",
    "def to_byte_tensor(item):\n",
    "    res = torch.ByteTensor(torch.ByteStorage.from_buffer(item.tobytes()))\n",
    "    w,h = item.size\n",
    "    return res.view(h,w,-1).permute(2,0,1)\n",
    "to_byte_tensor._order=20\n",
    "\n",
    "def to_float_tensor(item): return item.float().div_(255.)\n",
    "to_float_tensor._order=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [make_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PetsData(tfms=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,cls = data.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(im, figsize=(3,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(im.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor(): \n",
    "    def process(self, items): return items\n",
    "\n",
    "class CategoryProcessor(Processor):\n",
    "    def __init__(self): self.vocab=None\n",
    "    \n",
    "    def __call__(self, items):\n",
    "        #The vocab is defined on the first use.\n",
    "        if self.vocab is None:\n",
    "            self.vocab = uniqueify(items)\n",
    "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "        return [self.proc1(o) for o in items]\n",
    "    def proc1(self, item):  return self.otoi[item]\n",
    "    \n",
    "    def deprocess(self, idxs):\n",
    "        assert self.vocab is not None\n",
    "        return [self.deproc1(idx) for idx in idxs]\n",
    "    def deproc1(self, idx): return self.vocab[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
