---

title: train
keywords: 
sidebar: home_sidebar

summary: "Extensions to Learner that easily implement Callback"
---

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Additional-training-functions">Additional training functions<a class="anchor-link" href="#Additional-training-functions">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/train#train"><code>train</code></a> provides a number of extension methods that are added to <a href="/basic_train#Learner"><code>Learner</code></a> (see below for a list and details), along with three simple callbacks:</p>
<ul>
<li><a href="/train#ShowGraph"><code>ShowGraph</code></a></li>
<li><a href="/train#GradientClipping"><code>GradientClipping</code></a></li>
<li><a href="/train#BnFreeze"><code>BnFreeze</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Learner-extension-methods"><a href="/basic_train#Learner"><code>Learner</code></a> extension methods<a class="anchor-link" href="#Learner-extension-methods">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>These methods are automatically added to all <a href="/basic_train#Learner"><code>Learner</code></a> objects created after importing this module. They provide convenient access to a number of callbacks, without requiring them to be manually created.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4><a id=fit_one_cycle></a><code>fit_one_cycle</code></h4>
<blockquote><p><code>fit_one_cycle</code>(<code>learn</code>:<a href="/basic_train#Learner"><code>Learner</code></a>, <code>cyc_len</code>:<code>int</code>, <code>max_lr</code>:<code>Union</code>[<code>float</code>, <code>Collection</code>[<code>float</code>], <code>slice</code>]=<code>slice(None, 0.003, None)</code>, <code>moms</code>:<code>Point</code>=<code>(0.95, 0.85)</code>, <code>div_factor</code>:<code>float</code>=<code>25.0</code>, <code>pct_start</code>:<code>float</code>=<code>0.3</code>, <code>wd</code>:<code>float</code>=<code>None</code>, <code>callbacks</code>:<code>Optional</code>[<code>Collection</code>[<a href="/callback#Callback"><code>Callback</code></a>]]=<code>None</code>, <code>kwargs</code>)</p>
</blockquote>
<p>Fit a model following the 1cycle policy.  <a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L11">[source]</a></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Fit a model with 1cycle training. See <a href="/callbacks.one_cycle#OneCycleScheduler"><code>OneCycleScheduler</code></a> for details.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4><a id=lr_find></a><code>lr_find</code></h4>
<blockquote><p><code>lr_find</code>(<code>learn</code>:<a href="/basic_train#Learner"><code>Learner</code></a>, <code>start_lr</code>:<code>Floats</code>=<code>1e-07</code>, <code>end_lr</code>:<code>Floats</code>=<code>10</code>, <code>num_it</code>:<code>int</code>=<code>100</code>, <code>kwargs</code>:<code>Any</code>)</p>
</blockquote>
<p>Explore lr from <code>start_lr</code> to <code>end_lr</code> over <code>num_it</code> iterations in <code>learn</code>.  <a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L21">[source]</a></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>See <a href="/callbacks.lr_finder#LRFinder"><code>LRFinder</code></a> for details.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4><a id=to_fp16></a><code>to_fp16</code></h4>
<blockquote><p><code>to_fp16</code>(<code>learn</code>:<a href="/basic_train#Learner"><code>Learner</code></a>, <code>loss_scale</code>:<code>float</code>=<code>512.0</code>, <code>flat_master</code>:<code>bool</code>=<code>False</code>) → <a href="/basic_train#Learner"><code>Learner</code></a></p>
</blockquote>
<p>Transform <code>learn</code> in FP16 precision.  <a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L29">[source]</a></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>See <a href="/callbacks.fp16#MixedPrecision"><code>MixedPrecision</code></a> for details.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4><a id=mixup></a><code>mixup</code></h4>
<blockquote><p><code>mixup</code>(<code>learn</code>:<a href="/basic_train#Learner"><code>Learner</code></a>, <code>alpha</code>:<code>float</code>=<code>0.4</code>, <code>stack_x</code>:<code>bool</code>=<code>False</code>, <code>stack_y</code>:<code>bool</code>=<code>True</code>) → <a href="/basic_train#Learner"><code>Learner</code></a></p>
</blockquote>
<p>Add mixup <a href="https://arxiv.org/abs/1710.09412">https://arxiv.org/abs/1710.09412</a> to <code>learn</code>.  <a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L36">[source]</a></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>See <a href="/callbacks.mixup#MixUpCallback"><code>MixUpCallback</code></a> for more details.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A last extension method comes from the module tta.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4><a id=TTA></a><code>TTA</code></h4>
<blockquote><p><code>TTA</code>(<code>learn</code>:<a href="/basic_train#Learner"><code>Learner</code></a>, <code>beta</code>:<code>float</code>=<code>0.4</code>, <code>scale</code>:<code>float</code>=<code>1.35</code>, <code>is_test</code>:<code>bool</code>=<code>False</code>) → <code>Tensors</code>
<a href="https://github.com/fastai/fastai/blob/master/fastai/vision/tta.py#L36">[source]</a></p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Applies Test Time Augmentation to <code>learn</code> on the validation set or the test test (depending on <code>is_test</code>). We take the average of our regular predictions (with a weight <code>beta</code>) with the average of predictions obtained thourh augmented versions of the training set (with a weight <code>1-beta</code>). The transforms decided for the training set are applied with a few changes <code>scale</code> controls the scale for zoom (which isn't random), the cropping isn't random but we make sure to get the four corners of the image. Flipping isn't random but applied once on each of those corner images (so that makes 8 augmented versions total).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll show examples below using our MNIST sample.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span><span class="o">=</span><span class="n">URLs</span><span class="o">.</span><span class="n">get_mnist</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2><a id=ShowGraph></a><code>class</code> <code>ShowGraph</code></h2>
<blockquote><p><code>ShowGraph</code>(<code>learn</code>:<a href="/basic_train#Learner"><code>Learner</code></a>) :: <a href="/basic_train#LearnerCallback"><code>LearnerCallback</code></a></p>
</blockquote>
<p>Update a graph of learner stats and metrics after each epoch.  <a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L47">[source]</a></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">ConvLearner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">callback_fns</span><span class="o">=</span><span class="n">ShowGraph</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="imgs/train_graph.gif" alt="Training graph"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4><a id=ShowGraph.on_epoch_end></a><code>on_epoch_end</code></h4>
<blockquote><p><code>on_epoch_end</code>(<code>n_epochs</code>:<code>int</code>, <code>last_metrics</code>:<code>MetricsList</code>, <code>kwargs</code>) → <code>bool</code>
<a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L49">[source]</a></p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we have <code>last_metrics</code>, plot them in <code>self.pbar</code>. Set the size of the graph with <code>n_epochs</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2><a id=GradientClipping></a><code>class</code> <code>GradientClipping</code></h2>
<blockquote><p><code>GradientClipping</code>(<code>learn</code>:<a href="/basic_train#Learner"><code>Learner</code></a>, <code>clip</code>:<code>float</code>) :: <a href="/basic_train#LearnerCallback"><code>LearnerCallback</code></a></p>
</blockquote>
<p>To do gradient clipping during training.  <a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L67">[source]</a></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Clips gradient at a maximum absolute value of <code>clip</code> during training. For instance:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">ConvLearner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">,</span>
    <span class="n">callback_fns</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">GradientClipping</span><span class="p">,</span> <span class="n">clip</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total time: 00:11
epoch  train loss  valid loss  accuracy
0      0.086958    0.038721    0.989696  (00:11)

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4><a id=GradientClipping.on_backward_end></a><code>on_backward_end</code></h4>
<blockquote><p><code>on_backward_end</code>(<code>kwargs</code>)
<a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L71">[source]</a></p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Clip the gradients after they are computed but before the optimizer step.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2><a id=BnFreeze></a><code>class</code> <code>BnFreeze</code></h2>
<blockquote><p><code>BnFreeze</code>(<code>learn</code>:<a href="/basic_train#Learner"><code>Learner</code></a>) :: <a href="/basic_train#LearnerCallback"><code>LearnerCallback</code></a></p>
</blockquote>
<p>Freeze moving average statistics in all non-trainable batchnorm layers.  <a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L60">[source]</a></p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For batchnorm layers where <code>requires_grad==False</code>, you generally don't want to update their moving average statistics, in order to avoid the model's statistics getting out of sync with its pre-trained weights. You can add this callback to automate this freezing of statistics (internally, it calls <code>eval</code> on these layers).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">ConvLearner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">callback_fns</span><span class="o">=</span><span class="n">BnFreeze</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total time: 00:07
epoch  train loss  valid loss  accuracy
0      0.079278    0.041832    0.985280  (00:07)

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4><a id=BnFreeze.on_epoch_begin></a><code>on_epoch_begin</code></h4>
<blockquote><p><code>on_epoch_begin</code>(<code>kwargs</code>:<code>Any</code>)
<a href="https://github.com/fastai/fastai/blob/master/fastai/train.py#L62">[source]</a></p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Set back the batchnorm layers on <code>eval</code> mode after the model has been set to <a href="/train#train"><code>train</code></a>.</p>

</div>
</div>
</div>
</div>
 

