{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.layers import *\n",
    "from local.data.all import *\n",
    "from local.notebook.showdoc import show_doc\n",
    "from local.optimizer import *\n",
    "from local.learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callback.progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress and logging callbacks\n",
    "\n",
    "> Callback and helper function to track progress of training or log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.utils.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProgressCallback -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class ProgressCallback(Callback):\n",
    "    \"A `Callback` to handle the display of progress bars\"\n",
    "    run_after=Recorder\n",
    "\n",
    "    def begin_fit(self):\n",
    "        assert hasattr(self.learn, 'recorder')\n",
    "        self.mbar = master_bar(list(range(self.n_epoch)))\n",
    "        self.mbar.on_iter_begin()\n",
    "        self.old_logger,self.learn.logger = self.logger,self._write_stats\n",
    "        self._write_stats(self.recorder.metric_names)\n",
    "\n",
    "    def begin_epoch(self):    self.mbar.update(self.epoch)\n",
    "    def begin_train(self):    self._launch_pbar()\n",
    "    def begin_validate(self): self._launch_pbar()\n",
    "    def after_train(self):    self.pbar.on_iter_end()\n",
    "    def after_validate(self): self.pbar.on_iter_end()\n",
    "    def after_batch(self):\n",
    "        self.pbar.update(self.iter+1)\n",
    "        self.pbar.comment = f'{self.smooth_loss:.4f}'\n",
    "\n",
    "    def _launch_pbar(self):\n",
    "        self.pbar = progress_bar(self.dl, parent=self.mbar)\n",
    "        self.pbar.update(0)\n",
    "\n",
    "    def after_fit(self):\n",
    "        self.mbar.on_iter_end()\n",
    "        self.learn.logger = self.old_logger\n",
    "\n",
    "    def _write_stats(self, log):\n",
    "        self.mbar.write([f'{l:.6f}' if isinstance(l, float) else str(l) for l in log], table=True)\n",
    "\n",
    "    _docs = dict(begin_fit=\"Setup the master bar over the epochs\",\n",
    "                 begin_epoch=\"Update the master bar\",\n",
    "                 begin_train=\"Launch a progress bar over the training dataloader\",\n",
    "                 begin_validate=\"Launch a progress bar over the validation dataloader\",\n",
    "                 after_train=\"Close the progress bar over the training dataloader\",\n",
    "                 after_validate=\"Close the progress bar over the validation dataloader\",\n",
    "                 after_batch=\"Update the current progress bar\",\n",
    "                 after_fit=\"Close the master bar\")\n",
    "\n",
    "defaults.callbacks = [TrainEvalCallback, Recorder, ProgressCallback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = synth_learner()\n",
    "learn.fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert not learn.progress.mbar.child.is_active\n",
    "lines = learn.progress.mbar.lines\n",
    "test_eq(learn.recorder.metric_names, lines[0])\n",
    "for i,(l,v) in enumerate(zip(lines[1:],learn.recorder.values)):\n",
    "    test_eq(l[:-1], [str(i)] + [f'{x:.6f}' for x in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ProgressCallback.begin_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ProgressCallback.begin_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ProgressCallback.begin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ProgressCallback.begin_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ProgressCallback.after_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ProgressCallback.after_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ProgressCallback.after_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(ProgressCallback.after_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShowGraphCallback -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ShowGraphCallback(Callback):\n",
    "    \"Update a graph of training and validation loss\"\n",
    "    run_after=ProgressCallback\n",
    "\n",
    "    def begin_fit(self):\n",
    "        self.nb_batches = []\n",
    "        assert hasattr(self.learn, 'progress')\n",
    "\n",
    "    def after_train(self): self.nb_batches.append(self.train_iter)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Plot validation loss in the pbar graph\"\n",
    "        rec = self.learn.recorder\n",
    "        iters = range_of(rec.losses)\n",
    "        val_losses = [v[1] for v in rec.values]\n",
    "        x_bounds = (0, (self.n_epoch - len(self.nb_batches)) * self.nb_batches[0] + len(rec.losses))\n",
    "        y_bounds = (0, max((max(Tensor(rec.losses)), max(Tensor(val_losses)))))\n",
    "        self.progress.mbar.update_graph([(iters, rec.losses), (self.nb_batches, val_losses)], x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "learn = synth_learner(cbs=ShowGraphCallback())\n",
    "learn.fit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSVLogger -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CSVLogger(Callback):\n",
    "    order=30 #Need to run after the recorder\n",
    "    \"Log the results displayed in `learn.path/fname`\"\n",
    "    def __init__(self, fname='history.csv', append=False):\n",
    "        self.fname,self.append = Path(fname),append\n",
    "\n",
    "    def read_log(self):\n",
    "        \"Convenience method to quickly access the log.\"\n",
    "        return pd.read_csv(self.path/self.fname)\n",
    "\n",
    "    def begin_fit(self):\n",
    "        \"Prepare file with metric names.\"\n",
    "        self.path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.file = (self.path/self.fname).open('a' if self.append else 'w')\n",
    "        self.file.write(','.join(self.recorder.metric_names) + '\\n')\n",
    "        self.old_logger,self.learn.logger = self.logger,self._write_line\n",
    "\n",
    "    def _write_line(self, log):\n",
    "        \"Write a line with `log` and call the old logger.\"\n",
    "        self.file.write(','.join([str(t) for t in log]) + '\\n')\n",
    "        self.old_logger(log)\n",
    "\n",
    "    def after_fit(self):\n",
    "        \"Close the file and clean up.\"\n",
    "        self.file.close()\n",
    "        self.learn.logger = self.old_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are appened to an existing file if `append`, or they overwrite it otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = synth_learner(cbs=CSVLogger())\n",
    "learn.fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CSVLogger.read_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = learn.csv_logger.read_log()\n",
    "test_eq(df.columns.values, learn.recorder.metric_names)\n",
    "for i,v in enumerate(learn.recorder.values):\n",
    "    test_close(df.iloc[i][:3], [i] + v)\n",
    "os.remove(learn.path/learn.csv_logger.fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CSVLogger.begin_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CSVLogger.after_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
