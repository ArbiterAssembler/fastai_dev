{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.all import *\n",
    "from local.tabular.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp tabular.core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular with rapids\n",
    "\n",
    "> Basic functions to preprocess tabular data before assembling it in a `DataBunch` on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "try: import cudf,nvcategory\n",
    "except: print(\"This requires rapids, see https://rapids.ai/ for installation details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularProcessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategorifyGPU(TabularProc):\n",
    "    \"Transform the categorical variables to that type.\"\n",
    "    order = 1\n",
    "    def setup(self, df, trn_idx=None):\n",
    "        self.categories = {}\n",
    "        for n in self.cat_names: \n",
    "            col = df[n] if trn_idx is None else df.loc[trn_idx, n]\n",
    "            if col.dtype != \"object\": col = col.astype(\"str\")\n",
    "            self.categories[n] = nvcategory.from_strings(col.data).keys()\n",
    "        \n",
    "    def __call__(self, df):\n",
    "        for n in self.cat_names:\n",
    "            if df[n].dtype != \"object\": df[n] = df[n].astype(\"str\")\n",
    "            df[n] = nvcategory.from_strings(df[n].data).set_keys(self.categories[n]).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(CategorifyGPU, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CategorifyGPU(cat_names='a')\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,0,2]}))\n",
    "cat.setup(df)\n",
    "test_eq(list(cat.categories['a'].to_host()), ['0','1','2'])\n",
    "cat(df)\n",
    "test_eq(df['a'].to_array(), np.array([0,1,2,0,2]))\n",
    "df1 = cudf.from_pandas(pd.DataFrame({'a':[1,0,3,-1,2]}))\n",
    "cat(df1)\n",
    "#Values that weren't in the training df are sent to -1 (na)\n",
    "test_eq(df1['a'].to_array(), np.array([1,0,-1,-1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CategorifyGPU(cat_names='a')\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,3,2]}))\n",
    "cat.setup(df, trn_idx=[0,1,2])\n",
    "test_eq(list(cat.categories['a'].to_host()), [\"0\",\"1\",\"2\"])\n",
    "cat(df)\n",
    "test_eq(df['a'].to_array(), np.array([0,1,2,-1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NormalizeGPU(TabularProc):\n",
    "    \"Normalize the continuous variables.\"\n",
    "    order = 2\n",
    "    def setup(self, df, trn_idx=None):\n",
    "        self.means,self.stds = {},{}\n",
    "        for n in self.cont_names:\n",
    "            col = (df[n] if trn_idx is None else df.loc[trn_idx,n])\n",
    "            self.means[n],self.stds[n] = col.mean(),col.std(ddof=0)\n",
    "    \n",
    "    def __call__(self, df):\n",
    "        for n in self.cont_names: df[n] = (df[n]-self.means[n]) / (1e-7 + self.stds[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(NormalizeGPU, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = NormalizeGPU(cont_names='a')\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,3,4]}))\n",
    "norm.setup(df)\n",
    "x = np.array([0,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_eq(norm.means, {'a': m})\n",
    "test_close(norm.stds['a'], s)\n",
    "norm(df)\n",
    "test_close(df['a'].to_array(), (x-m)/s)\n",
    "df1 = cudf.from_pandas(pd.DataFrame({'a':[5,6,7]}))\n",
    "norm(df1)\n",
    "test_close(df1['a'].to_array(), (np.array([5,6,7])-m)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = NormalizeGPU(cont_names='a')\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,3,4]}))\n",
    "norm.setup(df, trn_idx=[0,1,2])\n",
    "x = np.array([0,1,2])\n",
    "m,s = x.mean(),x.std()\n",
    "test_eq(norm.means, {'a': m})\n",
    "test_close(norm.stds['a'], s)\n",
    "norm(df)\n",
    "test_close(df['a'].to_array(), (np.array([0,1,2,3,4])-m)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_median(col):\n",
    "    \"Get the median of a cudf Series `col`\"\n",
    "    col = col.dropna().reset_index(drop=True)\n",
    "    return col.sort_values()[len(col)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FillMissingGPU(TabularProc):\n",
    "    \"Fill the missing values in continuous columns.\"\n",
    "    def __init__(self, cat_names=None, cont_names=None, fill_strategy=FillStrategy.median, add_col=True, fill_val=0.):\n",
    "        super().__init__(cat_names, cont_names)\n",
    "        self.fill_strategy,self.add_col,self.fill_val = fill_strategy,add_col,fill_val\n",
    "    \n",
    "    def setup(self, df, trn_idx=None):\n",
    "        self.na_dict = {}\n",
    "        for n in self.cont_names:\n",
    "            col = df[n] if trn_idx is None else df.loc[trn_idx,n]\n",
    "            if col.isnull().any():\n",
    "                if self.fill_strategy == FillStrategy.median:     filler = get_median(col)\n",
    "                elif self.fill_strategy == FillStrategy.constant: filler = self.fill_val\n",
    "                else: filler = col.dropna().value_counts().index[0]\n",
    "                self.na_dict[n] = filler\n",
    "                if self.add_col:\n",
    "                    df[n+'_na'] = df[n].isnull()\n",
    "                    if n+'_na' not in self.cat_names: self.cat_names.append(n+'_na')\n",
    "\n",
    "    def __call__(self, df):\n",
    "        for n in self.cont_names:\n",
    "            if n in self.na_dict:\n",
    "                if self.add_col: df[n+'_na'] = df[n].isnull()\n",
    "                df[n] = df[n].fillna(self.na_dict[n])\n",
    "            elif df[n].isnull().sum() != 0:\n",
    "                raise Exception(f\"\"\"There are nan values in field {n} but there were none in the training set given at setup. \n",
    "                Please fix those manually.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(FillMissingGPU, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill1,fill2,fill3 = (FillMissingGPU(cont_names='a', fill_strategy=s) \n",
    "                     for s in [FillStrategy.median, FillStrategy.constant, FillStrategy.most_common])\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,np.nan,1,2,3,4]}))\n",
    "df1 = df.copy(); df2 = df.copy()\n",
    "fill1.setup(df); fill2.setup(df1); fill3.setup(df2)\n",
    "test_eq(fill1.na_dict, {'a': 2.})\n",
    "test_eq(fill2.na_dict, {'a': 0})\n",
    "test_eq(fill3.na_dict, {'a': 1.0})\n",
    "for f in [fill1, fill2, fill3]: test_eq(f.cat_names, ['a_na'])\n",
    "\n",
    "fill1(df); fill2(df1); fill3(df2)\n",
    "for df_,v in zip([df, df1, df2], [2., 0., 1.]):\n",
    "    test_eq(df_['a'].to_array(), np.array([0, 1, v, 1, 2, 3, 4]))\n",
    "    test_eq(df_['a_na'].to_array(), np.array([0, 0, 1, 0, 0, 0, 0]))\n",
    "    \n",
    "dfa = cudf.from_pandas(pd.DataFrame({'a':[np.nan,0,np.nan]}))\n",
    "dfa1 = dfa.copy(); dfa2 = dfa.copy()\n",
    "fill1(dfa); fill2(dfa1); fill3(dfa2)\n",
    "for df_,v in zip([dfa, dfa1, dfa2], [2., 0., 1.]):\n",
    "    test_eq(df_['a'].to_array(), np.array([v, 0, v]))\n",
    "    test_eq(df_['a_na'].to_array(), np.array([1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularProcessor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TabularPreprocessorGPU():\n",
    "    \"An object that will preprocess dataframes using `procs`\"\n",
    "    def __init__(self, procs, cat_names=None, cont_names=None, cat_y=None, inplace=True):\n",
    "        self.cat_names,self.cont_names,self.cat_y,self.inplace = L(cat_names),L(cont_names),L(cat_y),inplace\n",
    "        self.procs = L(p if isinstance(p, type) else partial(TabularProc, func=p) for p in procs).sorted(key='order')\n",
    "    \n",
    "    def __call__(self, df, trn_idx=None):\n",
    "        \"Call each of `self.procs` on `df`, setup on `df[trn_idx]` if not None\"\n",
    "        df = df if self.inplace else df.copy()\n",
    "        if trn_idx is None:\n",
    "            for p in self.procs: p(df)\n",
    "        else:\n",
    "            self.procs,procs = [],self.procs\n",
    "            for p in procs: \n",
    "                p_ = p(cat_names=self.cat_names + self.cat_y if p==CategorifyGPU else self.cat_names, cont_names=self.cont_names)\n",
    "                p_.setup(df, trn_idx=trn_idx)\n",
    "                p_(df)\n",
    "                if p!= CategorifyGPU: self.cat_names,self.cont_names = p_.cat_names,p_.cont_names\n",
    "                else:\n",
    "                    self.classes = {n:'#na#'+L(p_.categories[n].to_host(), use_list=True) for n in self.cat_names + self.cat_y}\n",
    "                self.procs.append(p_)\n",
    "            for p in self.procs:\n",
    "                if isinstance(p, Normalize): self.means,self.stds = p.means,p.stds\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [NormalizeGPU, CategorifyGPU, FillMissingGPU, noop]\n",
    "proc = TabularPreprocessorGPU(procs, 'a', 'b', inplace=False)\n",
    "\n",
    "#Test reordering and partialize\n",
    "test_eq(proc.procs, [FillMissingGPU, proc.procs[1], CategorifyGPU, NormalizeGPU])\n",
    "test_eq(proc.procs[1].func, TabularProc)\n",
    "test_eq(proc.procs[1].keywords, {'func': noop})\n",
    "\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4]}))\n",
    "\n",
    "#Test setup and apply on df_trn\n",
    "df1 = proc(df, trn_idx=range_of(df))\n",
    "test_eq(df1['a'].to_array(), [0,1,2,1,1,2,0])\n",
    "test_eq(df1['b_na'].to_array(), [0,0,1,0,0,0,0])\n",
    "x = np.array([0,1,2,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_close(df1['b'].to_array(), (x-m)/s)\n",
    "test_eq(proc.classes, {'a': ['#na#','0','1','2'], 'b_na': ['#na#','False','True']})\n",
    "\n",
    "#Test apply on df_val\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[2,1,3], 'b':[4,5,np.nan]}))\n",
    "df1 = proc(df)\n",
    "test_eq(proc.classes, {'a': ['#na#','0','1','2'], 'b_na': ['#na#','False','True']})\n",
    "test_eq(df1['a'].to_array(), [2,1,-1])\n",
    "test_eq(df1['b_na'].to_array(), [0,0,1])\n",
    "x = np.array([4, 5, 2])\n",
    "test_close(df1['b'].to_array(), (x-m)/s)\n",
    "\n",
    "#Test apply on cat_y\n",
    "procs = [NormalizeGPU, CategorifyGPU, FillMissingGPU, noop]\n",
    "proc = TabularPreprocessorGPU(procs, 'a', 'b', cat_y='c', inplace=False)\n",
    "\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4], 'c': ['b','a','b','a','a','b','a']}))\n",
    "df1 = proc(df, trn_idx=range_of(df))\n",
    "test_eq(proc.cat_names, ['a', 'b_na'])\n",
    "test_eq(df1['a'].to_array(), [0,1,2,1,1,2,0])\n",
    "test_eq(df1['b_na'].to_array(), [0,0,1,0,0,0,0])\n",
    "test_eq(df1['c'].to_array(), [1,0,1,0,0,1,0])\n",
    "x = np.array([0,1,2,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_close(df1['b'].to_array(), (x-m)/s)\n",
    "test_eq(proc.classes, {'a': ['#na#','0','1','2'], 'b_na': ['#na#','False','True'], 'c': ['#na#','a','b']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def process_df_gpu(df, splits, procs, cat_names=None, cont_names=None, cat_y=None, inplace=True):\n",
    "    \"Process `df` with `procs` and returns the processed dataframe and the `TabularProcessorGPU` associated\"\n",
    "    proc = TabularPreprocessorGPU(procs, cat_names, cont_names, cat_y, inplace=inplace)\n",
    "    res = proc(df, trn_idx=splits[0])\n",
    "    return res,proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the same `splits` as you will use for splitting the data, so that the setup is only done on the training set. `cat_names` are the names of the categorical variables, `cont_names` the continous ones, `cat_y` are the names of the dependent variables that are categories. If `inplace=True`, processing is applied inplace, otherwis it creates a copy of `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TabularLine(pd.Series):\n",
    "    \"A line of a dataframe that knows how to show itself\"\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        if ctx is None: return self\n",
    "        else: return ctx.append(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorTabular(tuple):\n",
    "    \n",
    "    def get_ctxs(self, max_n=10, **kwargs):\n",
    "        n_samples = min(self[0].shape[0], max_n)\n",
    "        df = pd.DataFrame(index = range(n_samples))\n",
    "        return [df.iloc[i] for i in range(n_samples)]\n",
    "    \n",
    "    def display(self, ctxs): display_df(pd.DataFrame(ctxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReadTabLine(ItemTransform):\n",
    "    def __init__(self, proc): \n",
    "        self.proc = proc\n",
    "        self.o2is = {n: defaultdict(int, {v:i for i,v in enumerate(proc.classes[n])}) for n in proc.cat_names}\n",
    "    \n",
    "    def encodes(self, row): \n",
    "        cats = [self.o2is[n][row[n]] for n in self.proc.cat_names]\n",
    "        conts = [row[n] for n in self.proc.cont_names]\n",
    "        return TensorTabular((tensor(cats).long(),tensor(conts).float()))\n",
    "    \n",
    "    def decodes(self, o) -> TabularLine:\n",
    "        dic = {c: self.proc.classes[c][v] for v,c in zip(o[0], self.proc.cat_names)}\n",
    "        ms = getattr(self.proc, 'means', {c:0 for c in self.proc.cont_names})\n",
    "        ss = getattr(self.proc, 'stds',  {c:1 for c in self.proc.cont_names})\n",
    "        dic.update({c: (v*ss[c] + ms[c]).item() for v,c in zip(o[1], self.proc.cont_names)})\n",
    "        return pd.Series(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReadTabTarget(ItemTransform):\n",
    "    def __init__(self, proc): \n",
    "        self.proc = proc\n",
    "        assert len(proc.cat_y) == 1\n",
    "        self.o2i = defaultdict(int, {v:i for i,v in enumerate(proc.classes[proc.cat_y[0]])})\n",
    "    \n",
    "    def encodes(self, row): return self.o2i[row[self.proc.cat_y[0]]]-1\n",
    "    def decodes(self, o) -> Category: return self.proc.classes[self.proc.cat_y[0]][o+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = TfmdDS(df1, tfms=[[ReadTabLine(proc)], ReadTabTarget(proc)], use_list=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tds[1]\n",
    "test_eq(enc[0][0], tensor([2,1]))\n",
    "test_close(enc[0][1], tensor([-0.628828]))\n",
    "test_eq(enc[1], 0)\n",
    "\n",
    "dec = tds.decode(enc)\n",
    "assert isinstance(dec[0], TabularLine)\n",
    "test_close(dec[0], pd.Series({'a': 1, 'b_na': False, 'b': 1}))\n",
    "test_eq(dec[1], 'a')\n",
    "\n",
    "test_stdout(lambda: print(tds.show_at(1)), \"\"\"a               1\n",
    "b_na        False\n",
    "b               1\n",
    "category        a\n",
    "dtype: object\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(range_of(df))\n",
    "df1,proc = process_df(df, splits, procs=procs, cat_names=cat_names, cont_names=cont_names, cat_y=\"salary\", inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(df1, filts=splits, tfms=[[ReadTabLine(proc)], [ReadTabTarget(proc)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = dsrc.databunch(bs=64)\n",
    "dbch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
