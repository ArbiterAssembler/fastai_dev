{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.data.transform import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating *partially reversible functions*, which we call `Transform`s. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already.)\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. The following functionality is provided:\n",
    "\n",
    "- A `Transform` is created with an `encodes` and potentially `decodes` function. \n",
    "- `Pipeline` is a transform which composes transforms\n",
    "- `TfmdList` takes a collection and a transform, and provides an indexer (`__getitem__`) which dynamically applies the transform to the collection items.\n",
    "- `Tuplify` is a special `Trannsform` that takes a list of list of transforms or a list of `Pipeline`s, then aapplies them to the element it receives to return a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_func(t, name, *args, **kwargs):\n",
    "    \"Get the `t.name` (potentially partial-ized with `args` and `kwargs`) or `noop` if not defined\"\n",
    "    f = getattr(t, name, noop)\n",
    "    return f if not (args or kwargs) else partial(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for any kind of `t` supporting `getattr`, so a class or a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_func(operator, 'neg', 2)(), -2)\n",
    "test_eq(get_func(operator.neg, '__call__')(2), -2)\n",
    "test_eq(get_func(list, 'foobar')([2]), [2])\n",
    "t = get_func(torch, 'zeros', dtype=torch.int64)(5)\n",
    "test_eq(t.dtype, torch.int64)\n",
    "a = [2,1]\n",
    "get_func(list, 'sort')(a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforms, are built with multiple-dispatch: a given function can have several methods depending on the type of the object received. This is done directly with the `multimethod` module and type-annotation in `Transofrm`, but you can also use the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Func():\n",
    "    \"Basic wrapper around a `name` with `args` and `kwargs` to call on a given type\"\n",
    "    def __init__(self, name, *args, **kwargs): self.name,self.args,self.kwargs = name,args,kwargs\n",
    "    def __repr__(self): return f'sig: {self.name}({self.args}, {self.kwargs})'\n",
    "    def _get(self, t): return get_func(t, self.name, *self.args, **self.kwargs)\n",
    "    def __call__(self,t): return L(t).mapped(self._get) if is_listy(t) else self._get(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `Func` object on any module name or type, even a list of types. It will return the corresponding function (with a default to `noop` if nothing is found) or list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Func('sqrt')(math), math.sqrt)\n",
    "test_eq(Func('sqrt')(torch), torch.sqrt)\n",
    "\n",
    "@patch\n",
    "def powx(x:math, a): return math.pow(x,a)\n",
    "@patch\n",
    "def powx(x:torch, a): return torch.pow(x,a)\n",
    "tst = Func('powx',a=2)([math, torch])\n",
    "test_eq([f.func for f in tst], [math.powx, torch.powx])\n",
    "for t in tst: test_eq(t.keywords, {'a': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _Sig():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return Func(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Sig = _Sig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Sig, name=\"Sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sig` is just sugar-syntax to create a `Func` object more easily with the syntax `Sig.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Sig.sqrt()\n",
    "test_eq(f(math), math.sqrt)\n",
    "test_eq(f(torch), torch.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SelfFunc():\n",
    "    \"Search for `name` attribute and call it with `args` and `kwargs` on any object it's passed.\"\n",
    "    def __init__(self, nm, *args, **kwargs): self.nm,self.args,self.kwargs = nm,args,kwargs\n",
    "    def __repr__(self): return f'self: {self.nm}({self.args}, {self.kwargs})'\n",
    "    def __call__(self, o):\n",
    "        if not is_listy(o): return getattr(o,self.nm)(*self.args, **self.kwargs)\n",
    "        else: return [getattr(o_,self.nm)(*self.args, **self.kwargs) for o_ in o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between `Func` and `SelfFunc` is that `Func` will generate a function when you call it on a type. On the other hand, `SelfFunc` is already a function and each time you call it on an object it looks for the `name` attribute and call it on `args` and `kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = SelfFunc('sqrt')\n",
    "x = torch.tensor([4.])\n",
    "test_eq(tst(x), torch.tensor([2.]))\n",
    "assert isinstance(tst(x), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _SelfFunc():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return SelfFunc(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Self = _SelfFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Self, name=\"Self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Self` is just syntax sugar to create a `SelfFunc` object more easily with the syntax `Self.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Self.sqrt()\n",
    "x = torch.tensor([4.])\n",
    "test_eq(f(x), torch.tensor([2.]))\n",
    "assert isinstance(f(x), Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs):\n",
    "    \"Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order\"\n",
    "    if reverse: tfms = reversed(tfms)\n",
    "    for f in tfms:\n",
    "        if not is_enc: f = f.decode\n",
    "        x = f(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int  (x)->Int  : return x\n",
    "def to_float(x)->Float: return x\n",
    "def double(x): return x*2\n",
    "def half(x)->None: return x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compose(a, b, *fs):\n",
    "    test_eq_type(compose_tfms(a, tfms=map(Transform,fs)), b)\n",
    "\n",
    "test_compose(1,   Int(1),   to_int)\n",
    "test_compose(1,   Float(1), to_int,to_float)\n",
    "test_compose(1,   Float(2), to_int,to_float,double)\n",
    "test_compose(2.0, 2.0,      to_int,double,half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, x:float)->Float: return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "    \n",
    "tfms = [A(), Transform(math.sqrt)]\n",
    "t = compose_tfms(3., tfms=tfms)\n",
    "test_eq_type(t, Float(2.))\n",
    "test_eq(compose_tfms(t, tfms=tfms, is_enc=False), 1.)\n",
    "test_eq(compose_tfms(4., tfms=tfms, reverse=True), 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [A(as_item=False), Transform(math.sqrt, as_item=False)]\n",
    "test_eq(compose_tfms((9,3.), tfms=tfms), (3,2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def batch_to_samples(b, max_n=10):\n",
    "    \"'Transposes' a batch to (at most `max_n`) samples\"\n",
    "    if isinstance(b, Tensor): return b[:max_n]\n",
    "    return L(batch_to_samples(b_, max_n) for b_ in b).zipped()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tensor([1,2,3])\n",
    "test_eq(batch_to_samples([t,t+1], max_n=2), ([1,2],[2,3]))\n",
    "test_eq(batch_to_samples(tensor([1,2,3]), 10), tensor([1, 2, 3]))\n",
    "test_eq(batch_to_samples([tensor([1,2,3]), tensor([4,5,6])], 10), [(1, 4), (2, 5), (3, 6)])\n",
    "test_eq(batch_to_samples([tensor([1,2,3]), tensor([4,5,6])], 2), [(1, 4), (2, 5)])\n",
    "test_eq(batch_to_samples([tensor([1,2,3]), [tensor([4,5,6]),tensor([7,8,9])]], 10), \n",
    "        [(1, (4, 7)), (2, (5, 8)), (3, (6, 9))])\n",
    "test_eq(batch_to_samples([tensor([1,2,3]), [tensor([4,5,6]),tensor([7,8,9])]], 2), [(1, (4, 7)), (2, (5, 8))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mk_transform(f, as_item=True):\n",
    "    \"Convert function `f` to `Transform` if it isn't already one\"\n",
    "    return f if isinstance(f,Transform) else Transform(f, as_item=as_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline(GetAttr):\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup with types\"\n",
    "    def __init__(self, funcs=None, as_item=True, filt=None):\n",
    "        if not funcs: funcs=[noop]\n",
    "        if isinstance(funcs, Pipeline): funcs = funcs.fs\n",
    "        self.filt = filt\n",
    "        self.fs = L(funcs).mapped(mk_transform).sorted(key='order')\n",
    "        self.set_as_item(as_item)\n",
    "\n",
    "    def set_as_item(self, as_item):\n",
    "        self.as_item = as_item\n",
    "        for f in self.fs: f.as_item = as_item\n",
    "\n",
    "    def setup(self, items=None):\n",
    "        self.default = self.items = items\n",
    "        tfms,self.fs = self.fs,[]\n",
    "        for t in tfms: self.add(t,items)\n",
    "\n",
    "    def add(self,t, items=None):\n",
    "        getattr(t, 'setup', noop)(items)\n",
    "        getattr(t, 'process', noop)(items)\n",
    "        self.fs.append(t)\n",
    "\n",
    "    def __call__(self, o): return compose_tfms(o, tfms=self.fs, filt=self.filt)\n",
    "    def decode  (self, o): return compose_tfms(o, tfms=self.fs, is_enc=False, reverse=True, filt=self.filt)\n",
    "    def __repr__(self): return f\"Pipeline: {self.fs}\"\n",
    "    def __getitem__(self,i): return self.fs[i]\n",
    "    def decode_batch(self, b, max_n=10): return batch_to_samples(b, max_n=max_n).mapped(self.decode)\n",
    "    def __setstate__(self,data): self.__dict__.update(data)\n",
    "\n",
    "    # TODO: move show_batch here of TfmDS?\n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for f in reversed(self.fs):\n",
    "            res = self._show(o, ctx, **kwargs)\n",
    "            if res is not None: return res\n",
    "            o = f.decode(o, filt=self.filt)\n",
    "        return self._show(o, ctx, **kwargs)\n",
    "\n",
    "    def _show(self, o, ctx, **kwargs):\n",
    "        o1 = [o] if self.as_item else o\n",
    "        if not all(hasattr(o_, 'show') for o_ in o1): return\n",
    "        for o_ in o1: ctx = o_.show(ctx=ctx, **kwargs)\n",
    "        return 1 if ctx is None else ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `fs` on `o`\",\n",
    "         decode=\"Compose `decode` of all `fs` on `o`\",\n",
    "         show=\"Show `o`, a single item from a tuple, decoding as needed\",\n",
    "         add=\"Add transform `t`\",\n",
    "         decode_batch=\"`decode` all sample in a the batch `b`\",\n",
    "         set_as_item=\"Set value of `as_item` for all transforms\",\n",
    "         setup=\"Call each tfm's `setup` in order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple wrapper for `compose_tfm`. Handles adding transforms one at a time and calling setup on each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipeline is noop\n",
    "pipe = Pipeline()\n",
    "test_eq(pipe(1), 1)\n",
    "pipe.set_as_item(False)\n",
    "test_eq(pipe((1,)), (1,))\n",
    "# Check pickle works\n",
    "assert pickle.loads(pickle.dumps(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntFloatTfm(Transform):\n",
    "    def encodes(self, x)->Int: return x\n",
    "    def decodes(self, x)->Float: return x\n",
    "\n",
    "int_tfm=IntFloatTfm()\n",
    "\n",
    "def neg(x): return -x\n",
    "neg_tfm = Transform(neg, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([neg_tfm, int_tfm])\n",
    "\n",
    "start = 2.0\n",
    "t = pipe(start)\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq_type(pipe.decode(t), Float(start))\n",
    "test_stdout(lambda:pipe.show(t), '-2')\n",
    "\n",
    "pipe.set_as_item(False)\n",
    "test_stdout(lambda:pipe.show(pipe((1,2))), '-1\\n-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check opposite order\n",
    "pipe = Pipeline([int_tfm,neg_tfm])\n",
    "t = pipe(start)\n",
    "test_eq(t, -2)\n",
    "test_stdout(lambda:pipe.show(t), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, x)->int: return x\n",
    "    def decodes(self, x)->Float: return x\n",
    "    \n",
    "pipe = Pipeline([neg_tfm, A()])\n",
    "t = pipe(start)\n",
    "test_eq_type(t, -2)\n",
    "test_eq_type(pipe.decode(t), Float(start))\n",
    "test_stdout(lambda:pipe.show(t), '-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = (1,2)\n",
    "pipe.set_as_item(False)\n",
    "t = pipe(s2)\n",
    "test_eq_type(t, (-1,-2))\n",
    "test_eq_type(pipe.decode(t), (Float(1.),Float(2.)))\n",
    "test_stdout(lambda:pipe.show(t), '-1.0\\n-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def f1(x:TensorImage): return -x\n",
    "def f2(x)->Image.Image: return Image.open(x).resize((128,128))\n",
    "def f3(x:Image.Image)->TensorImage: return(tensor(array(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([f2,f3,f1])\n",
    "t = pipe(TEST_IMAGE)\n",
    "test_eq(type(t), TensorImage)\n",
    "test_eq(t, -tensor(f3(f2(TEST_IMAGE))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([f2,f3])\n",
    "t = pipe(TEST_IMAGE)\n",
    "ax = pipe.show(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check filtering is properly applied\n",
    "add1 = B()\n",
    "add1.filt = 1\n",
    "pipe = Pipeline([neg_tfm, A(), add1])\n",
    "test_eq(pipe(start), -2)\n",
    "pipe.filt=1\n",
    "test_eq(pipe(start), -1)\n",
    "pipe.filt=0\n",
    "test_eq(pipe(start), -2)\n",
    "for t in [None, 0, 1]:\n",
    "    pipe.filt=t\n",
    "    test_eq(pipe.decode(pipe(start)), start)\n",
    "    test_stdout(lambda: pipe.show(pipe(start)), \"-2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: method examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.decode_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_as_item(False)\n",
    "t = tensor([1,2,3])\n",
    "pipe.filt=1\n",
    "test_eq(pipe.decode_batch([t,t+1], max_n=2), [(0,-1),(-1,-2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the setup, the `Pipeline` starts with no transform and adds them one at a time, so that during its setup, each transfrom get the items processed up to its point and not after. Depending on the attribute `add_before_setup`, the transform is added after the setup (default behaivor) so it's not called on the items used for the setup, or before (in which case it's called on the values used for setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test is below with TfmdList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdBase(L):\n",
    "    \"Base class for transformed lists\"\n",
    "    def _gets(self, i): return L(self._get(i_) for i_ in mask2idxs(i))\n",
    "    def subset(self, idxs): return self._new(super()._gets(idxs))\n",
    "    def decode_at(self, idx): return self.decode(self[idx])\n",
    "    def show_at(self, idx, **kwargs): return self.show(self[idx], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdList(TfmdBase):\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of `items`\"\n",
    "    def __init__(self, items, tfms, do_setup=True, as_item=True, use_list=None, filt=None):\n",
    "        super().__init__(items, use_list=use_list)\n",
    "        if isinstance(tfms,TfmdList): tfms = tfms.tfms\n",
    "        if isinstance(tfms,Pipeline): do_setup=False\n",
    "        self.tfms = Pipeline(tfms, as_item=as_item, filt=filt)\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def _new(self, items, *args, **kwargs): return super()._new(items, tfms=self.tfms, do_setup=False, use_list=None, filt=self.filt)\n",
    "    def _get (self, i): return self.tfms(super()._get(i))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfms.fs}\"\n",
    "\n",
    "    # Delegating to `self.tfms`\n",
    "    def show(self, o, **kwargs): return self.tfms.show(o, **kwargs)\n",
    "    def setup(self): self.tfms.setup(self)\n",
    "    def decode(self, x, **kwargs): return self.tfms.decode(x, **kwargs)\n",
    "    def __call__(self, x, **kwargs): return self.tfms.__call__(x, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def filt(self): return self.tfms.filt\n",
    "    @filt.setter\n",
    "    def filt(self,v): self.tfms.filt = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(TfmdList,\n",
    "         setup=\"Transform setup with self\",\n",
    "         decode=\"From `Pipeline\",\n",
    "         show=\"From `Pipeline\",\n",
    "         decode_at=\"Decoded item at `idx`\",\n",
    "         show_at=\"Show item at `idx`\",\n",
    "         subset=\"New `TfmdList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfms` can either be a `Pipeline` or a list of transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TfmdList([1.,2.,3.], [neg_tfm, int_tfm])\n",
    "t = tl[1]\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq_type(tl.decode(t), Float(2.0))\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tl[1]\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq_type(tl.decode(t), Float(2.0))\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset([0,2])\n",
    "test_eq(p2, [-1,-3])\n",
    "test_eq(map(type, p2), (Int,Int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(a=[1,2,3],b=[2,3,4]))\n",
    "tl = TfmdList(df, lambda o: o.a)\n",
    "test_eq(tl[1,2], [2,3])\n",
    "p2 = tl.subset([1,2])\n",
    "test_eq(p2, [2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Cat(Transform):\n",
    "    order = 1\n",
    "    def __init__(self, subset_idx=None): self.subset_idx = subset_idx\n",
    "    def encodes(self, o)->int: return self.o2i[o]\n",
    "    def decodes(self, o)->Str: return self.vocab[o]\n",
    "    def setup(self, items): \n",
    "        if self.subset_idx is not None: items = items.subset(self.subset_idx)\n",
    "        self.vocab,self.o2i = uniqueify(L(items), sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o)->Str: return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "# Check that tfms are sorted by `order`\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl, (1,0,0,0,1))\n",
    "t = L(tl)\n",
    "test_eq(t, [1,0,0,0,1])\n",
    "test_eq(tl[-1], 1)\n",
    "test_eq(tl[0,1], (1,0))\n",
    "test_eq([tl.decode(o) for o in t], ('dog','cat','cat','cat','dog'))\n",
    "test_stdout(lambda:tl.show_at(0), \"dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(Transform):\n",
    "    def __init__(self):   self.a = 2\n",
    "    def encodes(self, x): return x+self.a\n",
    "    def decodes(self, x): return x-self.a\n",
    "    def setup(self, items): self.a = tensor(items).float().mean().item()\n",
    "\n",
    "tl1 = TfmdList([1,2,3,4], B())\n",
    "test_eq(tl1.tfms[0].a, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "tl1 = TfmdList([1.,2.,3.,4.], [neg_tfm, A(), add1])\n",
    "test_eq(tl1[2], -3)\n",
    "tl1.filt=1\n",
    "test_eq(tl1[2], -2)\n",
    "test_eq(tl1[[2,2]], [-2,-2])\n",
    "tl1.filt=0\n",
    "test_eq(tl1[2], -3)\n",
    "for t in [None, 0, 1]:\n",
    "    tl1.filt=t\n",
    "    test_eq(tl1.decode(tl1[1]), 2)\n",
    "    test_eq(tl1.decode_at(1), 2)\n",
    "    test_stdout(lambda: tl1.show_at(1), \"-2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdList.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl.decode_at(1),tl.decode(tl[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: tl.show_at(1), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdList.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TfmdDS(TfmdBase):\n",
    "    \"A dataset that creates a tuple from each `tfms`, passed thru `ds_tfms`\"\n",
    "    def __init__(self, items, tfms=None, do_setup=True, use_list=None, filt=None):\n",
    "        super().__init__(items, use_list=use_list)\n",
    "        self.tls = [TfmdList(items, t, do_setup=do_setup, filt=filt, use_list=use_list) for t in L(tfms)]\n",
    "\n",
    "    def _get(self, it): return tuple(tl._get(it) for tl in self.tls)\n",
    "    def __repr__(self): return coll_repr(self)\n",
    "    def decode(self, o): return tuple(it.decode(o_) for o_,it in zip(o,self.tls))\n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for o_,it in zip(o,self.tls): ctx = it.show(o_, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    @property\n",
    "    def filt(self): return self.tls[0].filt\n",
    "    @filt.setter\n",
    "    def filt(self,v):\n",
    "        for tl in self.tls: tl.filt = v\n",
    "\n",
    "    _docs=dict(\n",
    "        decode=\"Compose `decode` of all `tuple_tfms` then all `tfms` on `i`\",\n",
    "        show=\"Show item `o` in `ctx`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "tds = TfmdDS(items, [[neg_tfm,int_tfm]])\n",
    "test_eq(*tds[0], -1)\n",
    "test_eq(tds[0,1,2], [(-1,),(-2,),(-3,)])\n",
    "test_eq(tds.decode_at(0), (1,))\n",
    "test_stdout(lambda:tds.show_at(1), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, o)->float: return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setup(self, items):\n",
    "        its = tensor(items).float()\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "nrm = A()\n",
    "tds = TfmdDS(items, [[neg_tfm,int_tfm], [neg_tfm,nrm]])\n",
    "\n",
    "x,y = zip(*tds)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, (-1,-2,-3,-4,))\n",
    "test_eq(nrm.m, -2.5)\n",
    "test_stdout(lambda:tds.show_at(1), '-2')\n",
    "#TODO: do something here\n",
    "# test_eq(tds.m, tds.type_tfms[1].fs[1].m)\n",
    "# test_eq(tds.s, tds.type_tfms[1].fs[1].s)\n",
    "#Attributes are set to all parents progressively\n",
    "# test_eq(tds.tls[1].m, tds.type_tfms[1].fs[1].m)\n",
    "# test_eq(tds.tls[1].s, tds.type_tfms[1].fs[1].s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "class B(Transform):\n",
    "    def encodes(self, x)->int: return x+1\n",
    "    def decodes(self, x)->Int: return x-1\n",
    "add1 = B()\n",
    "add1.filt = 1\n",
    "\n",
    "tds = TfmdDS(items, [neg_tfm, [neg_tfm,int_tfm,add1]])\n",
    "test_eq(tds[1], [-2,-2])\n",
    "tds.filt=1\n",
    "test_eq(tds.filt, 1)\n",
    "test_eq(tds[1], [-2,-1])\n",
    "test_eq(tds[[1,1]], [[-2,-1], [-2,-1]])\n",
    "tds.filt=0\n",
    "test_eq(tds[1], [-2,-2])\n",
    "for t in [None, 0, 1]:\n",
    "    tds.filt=t\n",
    "    test_eq(tds.decode(tds[1]), [2,2])\n",
    "    test_eq(tds.decode_at(1), [2,2])\n",
    "    test_stdout(lambda: tds.show_at(1), \"-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add examples to method docs, or move them from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdDS.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdDS.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdDS.show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdDS.show_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
