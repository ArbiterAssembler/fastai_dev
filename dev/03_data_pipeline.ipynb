{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.data.transform import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating a composition of *partially reversible functions*. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already).\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. `Pipeline` is a transform which composes several `Transform`, knowing how to decode them or show an encoded item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_func(t, name, *args, **kwargs):\n",
    "    \"Get the `t.name` (potentially partial-ized with `args` and `kwargs`) or `noop` if not defined\"\n",
    "    f = getattr(t, name, noop)\n",
    "    return f if not (args or kwargs) else partial(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for any kind of `t` supporting `getattr`, so a class or a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_func(operator, 'neg', 2)(), -2)\n",
    "test_eq(get_func(operator.neg, '__call__')(2), -2)\n",
    "test_eq(get_func(list, 'foobar')([2]), [2])\n",
    "t = get_func(torch, 'zeros', dtype=torch.int64)(5)\n",
    "test_eq(t.dtype, torch.int64)\n",
    "a = [2,1]\n",
    "get_func(list, 'sort')(a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms are built with multiple-dispatch: a given function can have several methods depending on the type of the object received. This is done directly with the `multimethod` module and type-annotation in `Transform`, but you can also use the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Func():\n",
    "    \"Basic wrapper around a `name` with `args` and `kwargs` to call on a given type\"\n",
    "    def __init__(self, name, *args, **kwargs): self.name,self.args,self.kwargs = name,args,kwargs\n",
    "    def __repr__(self): return f'sig: {self.name}({self.args}, {self.kwargs})'\n",
    "    def _get(self, t): return get_func(t, self.name, *self.args, **self.kwargs)\n",
    "    def __call__(self,t): return L(t).mapped(self._get) if is_listy(t) else self._get(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `Func` object on any module name or type, even a list of types. It will return the corresponding function (with a default to `noop` if nothing is found) or list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Func('sqrt')(math), math.sqrt)\n",
    "test_eq(Func('sqrt')(torch), torch.sqrt)\n",
    "\n",
    "@patch\n",
    "def powx(x:math, a): return math.pow(x,a)\n",
    "@patch\n",
    "def powx(x:torch, a): return torch.pow(x,a)\n",
    "tst = Func('powx',a=2)([math, torch])\n",
    "test_eq([f.func for f in tst], [math.powx, torch.powx])\n",
    "for t in tst: test_eq(t.keywords, {'a': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _Sig():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return Func(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Sig = _Sig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Sig\" class=\"doc_header\"><code>Sig</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Sig</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Sig, name=\"Sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sig` is just sugar-syntax to create a `Func` object more easily with the syntax `Sig.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Sig.sqrt()\n",
    "test_eq(f(math), math.sqrt)\n",
    "test_eq(f(torch), torch.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs):\n",
    "    \"Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order\"\n",
    "    if reverse: tfms = reversed(tfms)\n",
    "    for f in tfms:\n",
    "        if not is_enc: f = f.decode\n",
    "        x = f(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int  (x)  :  return Int(x)\n",
    "def to_float(x):  return Float(x)\n",
    "def double(x): return x*2\n",
    "def half(x)->None: return x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compose(a, b, *fs):\n",
    "    test_eq_type(compose_tfms(a, tfms=map(Transform,fs)), b)\n",
    "\n",
    "test_compose(1,   Int(1),   to_int)\n",
    "test_compose(1,   Float(1), to_int,to_float)\n",
    "test_compose(1,   Float(2), to_int,to_float,double)\n",
    "test_compose(2.0, 2.0,      to_int,double,half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, x:float):  return Float(x+1)\n",
    "    def decodes(self, x): return x-1\n",
    "    \n",
    "tfms = [A(), Transform(math.sqrt)]\n",
    "t = compose_tfms(3., tfms=tfms)\n",
    "test_eq_type(t, Float(2.))\n",
    "test_eq(compose_tfms(t, tfms=tfms, is_enc=False), 1.)\n",
    "test_eq(compose_tfms(4., tfms=tfms, reverse=True), 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [A(as_item=False), Transform(math.sqrt, as_item=False)]\n",
    "test_eq(compose_tfms((9,3.), tfms=tfms), (3,2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def batch_to_samples(b, max_n=10):\n",
    "    \"'Transposes' a batch to (at most `max_n`) samples\"\n",
    "    if isinstance(b, Tensor): return b[:max_n]\n",
    "    else:\n",
    "        res = L(b).mapped(partial(batch_to_samples,max_n=max_n))\n",
    "        return L(retain_types(res.zipped(), [b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tensor([1,2,3])\n",
    "test_eq(batch_to_samples([t,t+1], max_n=2), ([1,2],[2,3]))\n",
    "test_eq(batch_to_samples(tensor([1,2,3]), 10), tensor([1, 2, 3]))\n",
    "test_eq(batch_to_samples([tensor([1,2,3]), tensor([4,5,6])], 10), [(1, 4), (2, 5), (3, 6)])\n",
    "test_eq(batch_to_samples([tensor([1,2,3]), tensor([4,5,6])], 2), [(1, 4), (2, 5)])\n",
    "test_eq(batch_to_samples([tensor([1,2,3]), [tensor([4,5,6]),tensor([7,8,9])]], 10), \n",
    "        [(1, (4, 7)), (2, (5, 8)), (3, (6, 9))])\n",
    "test_eq(batch_to_samples([tensor([1,2,3]), [tensor([4,5,6]),tensor([7,8,9])]], 2), [(1, (4, 7)), (2, (5, 8))])\n",
    "\n",
    "t = TupleBase(tensor([1,2,3]),TensorBase([2,3,4]))\n",
    "test_eq_type(batch_to_samples(t)[0][1], TensorBase(2))\n",
    "test_eq(batch_to_samples(t).mapped(type), [TupleBase]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mk_transform(f, as_item=True):\n",
    "    \"Convert function `f` to `Transform` if it isn't already one\"\n",
    "    f = instantiate(f)\n",
    "    return f if isinstance(f,Transform) else Transform(f, as_item=as_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline:\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup with types\"\n",
    "    def __init__(self, funcs=None, as_item=False, filt=None):\n",
    "        if isinstance(funcs, Pipeline): funcs = funcs.fs\n",
    "        self.filt,self.default = filt,None\n",
    "        self.fs = L(ifnone(funcs,[noop])).mapped(mk_transform).sorted(key='order')\n",
    "        self.set_as_item(as_item)\n",
    "        for f in self.fs:\n",
    "            name = camel2snake(type(f).__name__)\n",
    "            a = getattr(self,name,None)\n",
    "            if a is not None: f = L(a)+f\n",
    "            setattr(self, name, f)\n",
    "\n",
    "    def set_as_item(self, as_item):\n",
    "        self.as_item = as_item\n",
    "        for f in self.fs: f.as_item = as_item\n",
    "\n",
    "    def setup(self, items=None):\n",
    "        self.items = items\n",
    "        tfms,self.fs = self.fs,L()\n",
    "        for t in tfms: self.add(t,items)\n",
    "\n",
    "    def add(self,t, items=None):\n",
    "        t.setup(items)\n",
    "        self.fs.append(t)\n",
    "\n",
    "    def __call__(self, o): return compose_tfms(o, tfms=self.fs, filt=self.filt)\n",
    "    def decode  (self, o): return compose_tfms(o, tfms=self.fs, is_enc=False, reverse=True, filt=self.filt)\n",
    "    def __repr__(self): return f\"Pipeline: {self.fs}\"\n",
    "    def __getitem__(self,i): return self.fs[i]\n",
    "    def decode_batch(self, b, max_n=10): return batch_to_samples(b, max_n=max_n).mapped(self.decode)\n",
    "    def __setstate__(self,data): self.__dict__.update(data)\n",
    "        \n",
    "    def __getattr__(self,k):\n",
    "        if k.startswith('_') or k=='fs': raise AttributeError(k)\n",
    "        res = sum(self.fs.attrgot(k).mapped(L), [])\n",
    "        if not res: raise AttributeError(k)\n",
    "        return res[0] if len(res)==1 else res\n",
    "            \n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for f in reversed(self.fs):\n",
    "            res = self._show(o, ctx, **kwargs)\n",
    "            if res is not None: return res\n",
    "            o = f.decode(o, filt=self.filt)\n",
    "        return self._show(o, ctx, **kwargs)\n",
    "\n",
    "    def _show(self, o, ctx, **kwargs):\n",
    "        o1 = [o] if self.as_item or not is_listy(o) else o\n",
    "        if not all(hasattr(o_, 'show') for o_ in o1): return\n",
    "        for o_ in o1: ctx = o_.show(ctx=ctx, **kwargs)\n",
    "        return ifnone(ctx,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `fs` on `o`\",\n",
    "         decode=\"Compose `decode` of all `fs` on `o`\",\n",
    "         show=\"Show `o`, a single item from a tuple, decoding as needed\",\n",
    "         add=\"Add transform `t`\",\n",
    "         decode_batch=\"`decode` all sample in a the batch `b`\",\n",
    "         set_as_item=\"Set value of `as_item` for all transforms\",\n",
    "         setup=\"Call each tfm's `setup` in order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline` is a wrapper for `compose_tfm`. You can pass instances of `Transform` or regular functions in `funcs`, the `Pipeline` will wrap them all in `Transform` (and instantiat them if needed) during the initialization. It handles the transform `setup` by adding them one at a time and calling setup on each, goes through them in order in `__call__` or `decode` and can `show` an object by applying decoding the transforms up until the point it gets an object that knows how to show itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipeline is noop\n",
    "pipe = Pipeline()\n",
    "test_eq(pipe(1), 1)\n",
    "pipe.set_as_item(False)\n",
    "test_eq(pipe((1,)), (1,))\n",
    "# Check pickle works\n",
    "assert pickle.loads(pickle.dumps(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntFloatTfm(Transform):\n",
    "    def encodes(self, x):  return Int(x)\n",
    "    def decodes(self, x):  return Float(x)\n",
    "    foo=1\n",
    "\n",
    "int_tfm=IntFloatTfm()\n",
    "\n",
    "def neg(x): return -x\n",
    "neg_tfm = Transform(neg, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([neg_tfm, int_tfm])\n",
    "\n",
    "start = 2.0\n",
    "t = pipe(start)\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq_type(pipe.decode(t), Float(start))\n",
    "test_stdout(lambda:pipe.show(t), '-2')\n",
    "\n",
    "pipe.set_as_item(False)\n",
    "test_stdout(lambda:pipe.show(pipe((1,2))), '-1\\n-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms are available as attributes named with the snake_case version of the names of their types. Attributes in transforms can be directly accessed as attributes of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(pipe.int_float_tfm, int_tfm)\n",
    "test_eq(pipe.foo, 1)\n",
    "\n",
    "pipe = Pipeline([int_tfm, int_tfm])\n",
    "pipe.int_float_tfm\n",
    "test_eq(pipe.int_float_tfm[0], int_tfm)\n",
    "test_eq(pipe.foo, [1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check opposite order\n",
    "pipe = Pipeline([int_tfm,neg_tfm])\n",
    "t = pipe(start)\n",
    "test_eq(t, -2)\n",
    "test_stdout(lambda:pipe.show(t), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, x):  return int(x)\n",
    "    def decodes(self, x):  return Float(x)\n",
    "    \n",
    "pipe = Pipeline([neg_tfm, A])\n",
    "t = pipe(start)\n",
    "test_eq_type(t, -2)\n",
    "test_eq_type(pipe.decode(t), Float(start))\n",
    "test_stdout(lambda:pipe.show(t), '-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = (1,2)\n",
    "pipe.set_as_item(False)\n",
    "t = pipe(s2)\n",
    "test_eq_type(t, (-1,-2))\n",
    "test_eq_type(pipe.decode(t), (Float(1.),Float(2.)))\n",
    "test_stdout(lambda:pipe.show(t), '-1.0\\n-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def f1(x:TensorImage): return -x\n",
    "def f2(x): return Image.open(x).resize((128,128))\n",
    "def f3(x:Image.Image): return(TensorImage(array(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([f2,f3,f1])\n",
    "t = pipe(TEST_IMAGE)\n",
    "test_eq(type(t), TensorImage)\n",
    "test_eq(t, -tensor(f3(f2(TEST_IMAGE))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([f2,f3])\n",
    "t = pipe(TEST_IMAGE)\n",
    "ax = pipe.show(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check filtering is properly applied\n",
    "add1 = B()\n",
    "add1.filt = 1\n",
    "pipe = Pipeline([neg_tfm, A(), add1])\n",
    "test_eq(pipe(start), -2)\n",
    "pipe.filt=1\n",
    "test_eq(pipe(start), -1)\n",
    "pipe.filt=0\n",
    "test_eq(pipe(start), -2)\n",
    "for t in [None, 0, 1]:\n",
    "    pipe.filt=t\n",
    "    test_eq(pipe.decode(pipe(start)), start)\n",
    "    test_stdout(lambda: pipe.show(pipe(start)), \"-2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: method examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.decode_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_as_item(False)\n",
    "t = tensor([1,2,3])\n",
    "pipe.filt=1\n",
    "test_eq(pipe.decode_batch([t,t+1], max_n=2), [(0,-1),(-1,-2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Pipeline.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the setup, the `Pipeline` starts with no transform and adds them one at a time, so that during its setup, each transform gets the items processed up to its point and not after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test is below with TfmdList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdBase(L):\n",
    "    \"Base class for transformed lists\"\n",
    "    def _gets(self, i): return L(self._get(i_) for i_ in mask2idxs(i))\n",
    "    def subset(self, idxs): return self._new(super()._gets(idxs))\n",
    "    def decode_at(self, idx): return self.decode(self[idx])\n",
    "    def show_at(self, idx, **kwargs): return self.show(self[idx], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdList(TfmdBase):\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of `items`\"\n",
    "    def __init__(self, items, tfms, do_setup=True, as_item=True, use_list=None, filt=None):\n",
    "        super().__init__(items, use_list=use_list)\n",
    "        if isinstance(tfms,TfmdList): tfms = tfms.tfms\n",
    "        if isinstance(tfms,Pipeline): do_setup=False\n",
    "        self.tfms = Pipeline(tfms, as_item=as_item, filt=filt)\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def _new(self, items, *args, **kwargs): return super()._new(items, tfms=self.tfms, do_setup=False, use_list=None, filt=self.filt)\n",
    "    def _get (self, i): return self.tfms(super()._get(i))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfms.fs}\"\n",
    "\n",
    "    # Delegating to `self.tfms`\n",
    "    def show(self, o, **kwargs): return self.tfms.show(o, **kwargs)\n",
    "    def setup(self): self.tfms.setup(self)\n",
    "    def decode(self, x, **kwargs): return self.tfms.decode(x, **kwargs)\n",
    "    def __call__(self, x, **kwargs): return self.tfms.__call__(x, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def filt(self): return self.tfms.filt\n",
    "    @filt.setter\n",
    "    def filt(self,v): self.tfms.filt = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(TfmdList,\n",
    "         setup=\"Transform setup with self\",\n",
    "         decode=\"From `Pipeline\",\n",
    "         show=\"From `Pipeline\",\n",
    "         decode_at=\"Decoded item at `idx`\",\n",
    "         show_at=\"Show item at `idx`\",\n",
    "         subset=\"New `TfmdList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TfmdList` combines a collection of object with a `Pipeline`. `tfms` can either be a `Pipeline` or a list of transforms, in which case, it will wrap them in a `Pipeline`. `use_list` is passed along to `L` with the `items`, `as_item` and `filt` are passed to each transform of the `Pipeline`. `do_setup` indicates if the `Pipeline.setup` method should be called during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TfmdList([1.,2.,3.], [neg_tfm, int_tfm])\n",
    "t = tl[1]\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq_type(tl.decode(t), Float(2.0))\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tl[1]\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq_type(tl.decode(t), Float(2.0))\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset([0,2])\n",
    "test_eq(p2, [-1,-3])\n",
    "test_eq(map(type, p2), (Int,Int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(a=[1,2,3],b=[2,3,4]))\n",
    "tl = TfmdList(df, lambda o: o.a)\n",
    "test_eq(tl[1,2], [2,3])\n",
    "p2 = tl.subset([1,2])\n",
    "test_eq(p2, [2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Cat(Transform):\n",
    "    order = 1\n",
    "    def __init__(self, subset_idx=None): self.subset_idx = subset_idx\n",
    "    def encodes(self, o):  return int(self.o2i[o])\n",
    "    def decodes(self, o):  return Str(self.vocab[o])\n",
    "    def setups(self, items): \n",
    "        if self.subset_idx is not None: items = items.subset(self.subset_idx)\n",
    "        self.vocab,self.o2i = uniqueify(L(items), sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o):  return Str(o.split('_')[0])\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "# Check that tfms are sorted by `order`\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl, (1,0,0,0,1))\n",
    "t = L(tl)\n",
    "test_eq(t, [1,0,0,0,1])\n",
    "test_eq(tl[-1], 1)\n",
    "test_eq(tl[0,1], (1,0))\n",
    "test_eq([tl.decode(o) for o in t], ('dog','cat','cat','cat','dog'))\n",
    "test_stdout(lambda:tl.show_at(0), \"dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(Transform):\n",
    "    def __init__(self):   self.a = 2\n",
    "    def encodes(self, x): return x+self.a\n",
    "    def decodes(self, x): return x-self.a\n",
    "    def setups(self, items): self.a = tensor(items).float().mean().item()\n",
    "\n",
    "tl1 = TfmdList([1,2,3,4], B())\n",
    "test_eq(tl1.tfms[0].a, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "tl1 = TfmdList([1.,2.,3.,4.], [neg_tfm, A(), add1])\n",
    "test_eq(tl1[2], -3)\n",
    "tl1.filt=1\n",
    "test_eq(tl1[2], -2)\n",
    "test_eq(tl1[[2,2]], [-2,-2])\n",
    "tl1.filt=0\n",
    "test_eq(tl1[2], -3)\n",
    "for t in [None, 0, 1]:\n",
    "    tl1.filt=t\n",
    "    test_eq(tl1.decode(tl1[1]), 2)\n",
    "    test_eq(tl1.decode_at(1), 2)\n",
    "    test_stdout(lambda: tl1.show_at(1), \"-2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdList.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl.decode_at(1),tl.decode(tl[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: tl.show_at(1), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdList.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TfmdDS(TfmdBase):\n",
    "    \"A dataset that creates a tuple from each `tfms`, passed thru `ds_tfms`\"\n",
    "    def __init__(self, items, tfms=None, do_setup=True, use_list=None, filt=None):\n",
    "        super().__init__(items, use_list=use_list)\n",
    "        if tfms is None: tms = [None]\n",
    "        self.tls = [TfmdList(items, t, do_setup=do_setup, filt=filt, use_list=use_list) for t in L(tfms)]\n",
    "\n",
    "    def _get(self, it): return tuple(tl._get(it) for tl in self.tls)\n",
    "    def __repr__(self): return coll_repr(self)\n",
    "    def decode(self, o): return tuple(it.decode(o_) for o_,it in zip(o,self.tls))\n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        for o_,it in zip(o,self.tls): ctx = it.show(o_, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    @property\n",
    "    def filt(self): return self.tls[0].filt\n",
    "    @filt.setter\n",
    "    def filt(self,v):\n",
    "        for tl in self.tls: tl.filt = v\n",
    "\n",
    "    _docs=dict(\n",
    "        decode=\"Compose `decode` of all `tuple_tfms` then all `tfms` on `i`\",\n",
    "        show=\"Show item `o` in `ctx`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TfmdDS` creates a tuple from `items` (typically input,target) by applying each list of `Transform` (or `Pipeline`) in `tfms` to them. Note that if `tfms` contains only one list of `tfms`, the items given by `TfmdDS` will be tuples of one element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "tds = TfmdDS(items, [[neg_tfm,int_tfm]])\n",
    "test_eq(*tds[0], -1)\n",
    "test_eq(tds[0,1,2], [(-1,),(-2,),(-3,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setups(self, items):\n",
    "        its = tensor(items).float()\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "nrm = A()\n",
    "tds = TfmdDS(items, [[neg_tfm,int_tfm], [neg_tfm,nrm]])\n",
    "\n",
    "x,y = zip(*tds)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, (-1,-2,-3,-4,))\n",
    "test_eq(nrm.m, -2.5)\n",
    "test_stdout(lambda:tds.show_at(1), '-2')\n",
    "#TODO: do something here\n",
    "# test_eq(tds.m, tds.type_tfms[1].fs[1].m)\n",
    "# test_eq(tds.s, tds.type_tfms[1].fs[1].s)\n",
    "#Attributes are set to all parents progressively\n",
    "# test_eq(tds.tls[1].m, tds.type_tfms[1].fs[1].m)\n",
    "# test_eq(tds.tls[1].s, tds.type_tfms[1].fs[1].s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "class B(Transform):\n",
    "    def encodes(self, x)->None:  return int(x+1)\n",
    "    def decodes(self, x):        return Int(x-1)\n",
    "\n",
    "add1 = B()\n",
    "add1.filt = 1\n",
    "\n",
    "tds = TfmdDS(items, [neg_tfm, [neg_tfm,int_tfm,add1]])\n",
    "test_eq(tds[1], [-2,-2])\n",
    "tds.filt=1\n",
    "test_eq(tds.filt, 1)\n",
    "test_eq(tds[1], [-2,-1])\n",
    "test_eq(tds[[1,1]], [[-2,-1], [-2,-1]])\n",
    "tds.filt=0\n",
    "test_eq(tds[1], [-2,-2])\n",
    "for t in [None, 0, 1]:\n",
    "    tds.filt=t\n",
    "    test_eq(tds.decode(tds[1]), [2,2])\n",
    "    test_eq(tds.decode_at(1), [2,2])\n",
    "    test_stdout(lambda: tds.show_at(1), \"-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "tds = TfmdDS(items, [[neg_tfm,int_tfm]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdDS.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(*tds[0], -1)\n",
    "test_eq(*tds.decode((-1,)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdDS.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tds.decode_at(0), (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdDS.show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda:tds.show(tds[1]), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TfmdDS.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda:tds.show_at(1), '-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
