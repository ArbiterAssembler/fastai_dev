{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.data.core import *\n",
    "from local.data.transform import *\n",
    "from local.data.pipeline import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source\n",
    "> Base container for all the items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def all_union(sets):\n",
    "    \"Set of union of all `sets` (each `setified` if needed)\"\n",
    "    return set().union(*(map(setify,sets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [[1,2],[2,3]]\n",
    "test_eq(all_union(sets), {1,2,3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def all_disjoint(sets):\n",
    "    \"`True` iif no element appears in more than one item of `sets`\"\n",
    "    return sum(map(len,sets))==len(all_union(sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not all_disjoint(sets)\n",
    "assert all_disjoint([[1,2],[3,4]])\n",
    "assert all_disjoint([[1,2],[]])\n",
    "assert all_disjoint([[1,2]])\n",
    "assert all_disjoint([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSource -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _mk_subset(self, i):\n",
    "    tfms = [o.tfms for o in self.tls]\n",
    "    return TfmdDS(L._gets(self, self.filts[i]), tfms=tfms, do_setup=False, filt=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _FiltTfmdList(TfmdList):\n",
    "    \"Like `TfmdList` but with filters and train/valid attribute, for proper setup\"\n",
    "    def __init__(self, items, tfms, filt_idx, do_setup=True, use_list=None):\n",
    "        self.filt_idx = filt_idx\n",
    "        super().__init__(items, tfms, do_setup=do_setup, as_item=True, use_list=use_list, filt=None)\n",
    "\n",
    "    def _new(self, items, *args, **kwargs): return super()._new(items, tfms=self.tfms, filt_idx=self.filt_idx, do_setup=False, use_list=None)\n",
    "    def subset(self, i): return _mk_subset(self, i)\n",
    "    def _get(self, i):\n",
    "        self.filt = self.filt_idx[i]\n",
    "        return super()._get(i)\n",
    "\n",
    "_FiltTfmdList.train,_FiltTfmdList.valid = add_props(lambda i,x: x.subset(i), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataSource(TfmdDS):\n",
    "    \"Applies a `tfm` to filtered subsets of `items`\"\n",
    "    def __init__(self, items, tfms=None, filts=None, do_setup=True):\n",
    "        super(TfmdDS,self).__init__(items, use_list=None)\n",
    "        if filts is None: filts = [range_of(items)]\n",
    "        self.filts = L(mask2idxs(filt) for filt in filts)\n",
    "\n",
    "        # Create map from item id to filter id\n",
    "        assert all_disjoint(self.filts)\n",
    "        self.filt_idx = L([None]*len(self.items))\n",
    "        for i,f in enumerate(self.filts): self.filt_idx[f] = i\n",
    "        self.tls = [_FiltTfmdList(self.items, t, self.filt_idx, do_setup=do_setup) for t in L(tfms)]\n",
    "\n",
    "    def __repr__(self): return '\\n'.join(map(str,self.subsets())) + f'\\ntls - {self.tls}'\n",
    "    def subsets(self): return map(self.subset, range_of(self.filts))\n",
    "    def subset(self, i): return _mk_subset(self, i)\n",
    "    def _get(self, i):\n",
    "        self.filt = self.filt_idx[i]\n",
    "        return super()._get(i)\n",
    "\n",
    "    @delegates(TfmdDL.__init__)\n",
    "    def databunch(self, bs=16, val_bs=None, shuffle_train=True, **kwargs):\n",
    "        n = len(self.filts)-1\n",
    "        bss = [bs] + [2*bs]*n if val_bs is None else [bs] + [val_bs]*n\n",
    "        shuffles = [shuffle_train] + [False]*n\n",
    "        return DataBunch(*[TfmdDL(self.subset(i), bs=b, shuffle=s, drop_last=s, **kwargs)\n",
    "                           for i,(b,s) in enumerate(zip(bss, shuffles))])\n",
    "\n",
    "DataSource.train,DataSource.valid = add_props(lambda i,x: x.subset(i), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(DataSource,\n",
    "         subset=\"Filtered `DsrcSubset` `i`\",\n",
    "         subsets=\"Iterator for all subsets\",\n",
    "         databunch=\"Create a `DataBunch`\",\n",
    "         show=\"Show item `o` in `ctx`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataSource` provides filtering and transformation capabilities to a list of items. Although it has all the attributes of `PipedList` (since it's a subclass) they are mainly used internally; you will generally want to instead access its `subset`s.\n",
    "\n",
    "If you don't pass any filters or transforms, it simply provides a single subset (of type `DsrcSubset`) with the same behavior as a `L`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [0,1,2,3,4]\n",
    "dsrc = DataSource(inp, tfms=[None])\n",
    "\n",
    "test_eq(len(dsrc.filts), 1)\n",
    "test_eq(*dsrc[2], 2)          # Retrieve one item (subset 0 is the default)\n",
    "test_eq(dsrc[1,2], [(1,),(2,)])    # Retrieve two items by index\n",
    "mask = [True,False,False,True,False]\n",
    "test_eq(dsrc[mask], [(0,),(3,)])   # Retrieve two items by mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = pd.DataFrame(dict(a=[5,1,2,3,4]))\n",
    "dsrc = DataSource(inp, tfms=itemgetter(0)).subset(0)\n",
    "test_eq(*dsrc[2], (2,))          # Retrieve one item (subset 0 is the default)\n",
    "test_eq(dsrc[1,2], [(1,),(2,)])    # Retrieve two items by index\n",
    "mask = [True,False,False,True,False]\n",
    "test_eq(dsrc[mask], [(5,),(3,)])   # Retrieve two items by mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `filts` to the `DataSource` constructor allows you to create multiple subsets, each of type `DsrcSubset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filts can be indices\n",
    "dsrc = DataSource(range(5), tfms=[None], filts=[tensor([0,2]), [1,3,4]])\n",
    "\n",
    "test_eq(len(dsrc.filts), 2)\n",
    "test_eq(dsrc.subset(0), [(0,),(2,)])\n",
    "test_eq(dsrc.train, [(0,),(2,)])       # Subset 0 is aliased to `train`\n",
    "test_eq(dsrc.subset(1), [(1,),(3,),(4,)])\n",
    "test_eq(dsrc.valid, [(1,),(3,),(4,)])     # Subset 1 is aliased to `valid`\n",
    "test_eq(*dsrc.valid[2], 4)\n",
    "assert '[(1,),(3,),(4,)]' in str(dsrc) and '[(0,),(2,)]' in str(dsrc)\n",
    "dsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filts can be boolean masks (they don't have to cover all items, but must be disjoint)\n",
    "filts = [[False,True,True,False,True], [True,False,False,False,False]]\n",
    "dsrc = DataSource(range(5), tfms=[None], filts=filts)\n",
    "\n",
    "test_eq(dsrc.train, [(1,),(2,),(4,)])\n",
    "test_eq(dsrc.valid, [(0,)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass `tfms` to have transformations applied before returning items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transforms to all items\n",
    "tfm = [[lambda x: x*2,lambda x: x+1]]\n",
    "filts = [[1,2],[0,3,4]]\n",
    "dsrc = DataSource(range(5), tfm, filts=filts)\n",
    "test_eq(dsrc.train,[(3,),(5,)])\n",
    "test_eq(dsrc.valid,[(1,),(7,),(9,)])\n",
    "test_eq(dsrc.train[False,True], [(5,)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subset index is also passed to your transform, so if it is an instance of `Transform` it will only be applied if the filt idx matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm(Transform):\n",
    "    filt=1\n",
    "    def encodes(self, x)     : return x*2\n",
    "    def decodes(self, x)->Str: return x//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(range(5), [_Tfm()], filts=[[1,2],[0,3,4]])\n",
    "test_eq(dsrc.train,[(1,),(2,)])\n",
    "test_eq(dsrc.valid,[(0,),(6,),(8,)])\n",
    "test_eq(dsrc.train[False,True], [(2,)])\n",
    "dsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test setup works with train attribute\n",
    "def _lbl(o): return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = Categorize()\n",
    "dsrc = DataSource(test_fns, [[tcat,_lbl]], filts=[[1,2,4], [0,3]])\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq(dsrc.train, [(0,),(0,),(1,)])\n",
    "test_eq(dsrc.valid, [(1,),(0,)])\n",
    "test_stdout(lambda: dsrc.train.show_at(0), \"cat\")\n",
    "#test_eq(dsrc.vocab, ['cat','dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test DataSource pickles\n",
    "dsrc1 = pickle.loads(pickle.dumps(dsrc))\n",
    "test_eq(dsrc.train, dsrc1.train)\n",
    "test_eq(dsrc.valid, dsrc1.valid)\n",
    "#test_eq(dsrc1.vocab, ['cat','dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(range(5), [_Tfm(),noop], filts=[[1,2],[0,3,4]])\n",
    "test_eq(dsrc.train,[(1,1),(2,2)])\n",
    "test_eq(dsrc.valid,[(0,0),(6,3),(8,4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataSource` Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You won't need to use many methods of `DataSource`, since normally you'll be accessing subsets, and therefore will be using `DsrcSubset` methods. However there are a few `DataSource` methods that may be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DataSource.databunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DataSource.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset 0 is aliased to the `train` property, and subset 1 is aliased to the `valid` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.subset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DataSource.subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
